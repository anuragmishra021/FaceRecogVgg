{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5-celebrity-faces-dataset', 'keras-pretrained-models']\n",
      "['resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"C:/Users/Anurag/Desktop/vggface/data_dir\"))\n",
    "print(os.listdir(\"C:/Users/Anurag/Desktop/vggface/data_dir/keras-pretrained-models/\"))\n",
    "\n",
    "data_dir = 'C:/Users/Anurag/Desktop/vggface/data_dir/5-celebrity-faces-dataset/data'\n",
    "vgg16weight = 'C:/Users/Anurag/Desktop/vggface/data_dir/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "resnet50weight = 'C:/Users/Anurag/Desktop/vggface/data_dir/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 200, 200\n",
    "\n",
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "validation_data_dir = os.path.join(data_dir, 'val')\n",
    "nb_train_samples = 93\n",
    "nb_validation_samples = 25\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "numclasses = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n",
      "Found 25 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    #shear_range=0.2,\n",
    "    vertical_flip=False,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16CNNtl(input_shape, outclass, sigma='sigmoid'):\n",
    "    \n",
    "    base_model = None\n",
    "    base_model = keras.applications.VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights(vgg16weight)\n",
    "        \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model\n",
    " \n",
    "def resnet50tl(input_shape, outclass, sigma='sigmoid'):\n",
    "    \n",
    "    base_model = None\n",
    "    base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights(resnet50weight)\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anurag\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "model = resnet50tl(input_shape, numclasses, 'softmax')\n",
    "lr = 1e-5\n",
    "decay = 1e-7 #0.0\n",
    "optimizer = RMSprop(lr=lr, decay=decay)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr = 0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"image_celeb.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anurag\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "nb_train_samples = 93\n",
    "nb_validation_samples = 25\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-63ec158a2699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get training and test loss histories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtraining_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create count of the number of epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "training_acc = history.history['acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "fig=plt.figure(figsize=(12, 4))\n",
    "# Visualize loss history\n",
    "fig.add_subplot(121)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Training Loss', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss/Acc')\n",
    "\n",
    "# Get training and test loss histories\n",
    "val_acc = history.history['val_acc']\n",
    "training_acc = history.history['acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "fig.add_subplot(122)\n",
    "plt.plot(epoch_count, val_acc, 'r--')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
